# === CHAT pelo endpoint OpenAI-compat do Ollama ===
spring.ai.openai.base-url=http://localhost:11434/v1
spring.ai.openai.api-key=ollama
spring.ai.openai.chat.options.model=lfm2-350m:latest

# Desliga embeddings do OpenAI (para não haver 2 beans de EmbeddingModel)
spring.ai.openai.embedding.enabled=false

# === EMBEDDINGS pela API nativa do Ollama (/api/embeddings) ===
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.embedding.enabled=true
spring.ai.ollama.embedding.options.model=nomic-embed-text

# Evita ambiguidade de ChatModel: desliga o Chat nativo do Ollama
spring.autoconfigure.exclude=\
org.springframework.ai.model.ollama.autoconfigure.OllamaChatAutoConfiguration
