spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=lfm2-350m   # tem de existir no "ollama list"
# Se precisares de embeddings do próprio Ollama (e tiveres um encoder):
# spring.ai.ollama.embedding.options.model=nome-do-encoder
